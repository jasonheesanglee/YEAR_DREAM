{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번 실습에서는 다음 내용들을 배웁니다.\n",
    "\n",
    "\n",
    "- 이제까지 배웠던 내용들을 합쳐서 원하는 데이터를 가져오는 코드를 작성합니다.\n",
    "\n",
    "\n",
    "- 원하는 지수 데이터를 불러오는 코드를 작성해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- td 태그중에 원하는 정보만을 따로 가져와야 합니다. (표를 자세히 보시면 왜 54개인지 알 수 있습니다.)\n",
    "\n",
    "\n",
    "- 날짜 태그의 규칙을 찾아서 td 태그들 중에 날짜를 가져옵니다.\n",
    "\n",
    "\n",
    "- 그런데 해당 페이지위에서 날짜 정보가 있는 tag에 대한 규칙을 찾기가 어렵습니다. 이럴 때 XPath 정보를 이용하여 바로 검색할 태그를 지정할 수 있습니다.\n",
    "\n",
    "\n",
    "- 아래 그림과 같이 우클릭을 해서 Copy XPath를 눌러줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sise_xpath](webcrawling/get_xpath.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td class=\"date\">2023.04.14</td>, <td class=\"date\">2023.04.13</td>, <td class=\"date\">2023.04.12</td>, <td class=\"date\">2023.04.11</td>, <td class=\"date\">2023.04.10</td>, <td class=\"date\">2023.04.07</td>]\n"
     ]
    }
   ],
   "source": [
    "# date에 대한 xpath\n",
    "# /html/body/div/table[1]/tbody/tr[4]/td[1]\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "page_no = 1\n",
    "page_url = f\"https://finance.naver.com/sise/sise_index_day.naver?code=KPI200&page={page_no}\"\n",
    "\n",
    "source = requests.get(page_url).text\n",
    "source = bs4.BeautifulSoup(source)\n",
    "\n",
    "dates = source.find_all(\"td\", class_ = \"date\")\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023.04.14'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023.04.14', '2023.04.13', '2023.04.12', '2023.04.11', '2023.04.10', '2023.04.07']\n"
     ]
    }
   ],
   "source": [
    "# tag를 통해 가져온 다음에 텍스트를 가져옵니다. 데이터는 text 형태로 tag 사이에 있습니다.\n",
    "# tag 사이에 껴있는 텍스트를 가져올 때 .text를 사용합니다.\n",
    "date_list = []\n",
    "\n",
    "for date in dates:\n",
    "    date_list.append(date.text)\n",
    "    \n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 날짜를 크롤링하는데 성공했습니다!!\n",
    "\n",
    "\n",
    "- 지금은 문자열인 이 정보를 실제 datetime 정보로 변환하여 사용하고 싶습니다. (이후에 pandas에서 결합하여 사용할 예정)\n",
    "\n",
    "\n",
    "- YYYY.MM.DD 형식의 문자열을 datetime 데이터 타입으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가져온 datetime을 YYYY.MM.DD 형태로 변환합니다.\n",
    "yyyy = \n",
    "mm = \n",
    "dd = \n",
    "\n",
    "this_date= dt.date(yyyy, mm, dd)\n",
    "this_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날짜정보를  date 타입으로 변경하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 변경 하는 기능은 계속해서 사용할 것이기 때문에, 함수로 정의합니다. 나중에 어떻게 코드상에서 사용되는지 눈여겨 보시면 좋습니다.\n",
    "\n",
    "def date_format(d):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return this_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 체결가(종가) 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 페이지 상의 날짜와 종가정보 전체 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['333.68', '333.09', '332.09', '330.87', '326.38', '323.36']\n"
     ]
    }
   ],
   "source": [
    "prices = source.find_all(\"td\", class_ = \"number_1\")\n",
    "price_list = []\n",
    "for price in prices[::4]:\n",
    "    price_list.append(price.text)\n",
    "    \n",
    "print(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 페이지에서 표의 태그들을 살펴보면, 체결가 이후로 전일비/등락률/거래량/거래대금 들도 같은 태그를 공유하고 있어, 4개씩 증가하는 것을 알 수 있습니다.\n",
    "\n",
    "\n",
    "- 이것을 규칙으로 number_1으로 추출한 태그는 24개이지만, 이 중에서 4의 배수로 건너뛰면서 추출하면 바로 체결가를 가져올 수 있다는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates 데이터를 활용하여 number_1에서 종가를 추출해봅니다.\n",
    "for n in range(len(dates)):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(this_date, this_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 크롤러의 마지막 관문이 남았습니다\n",
    "\n",
    "\n",
    "- 현재까지 하나의 페이지에서 크롤링 하는 것을 완료하였습니다.\n",
    "\n",
    "\n",
    "- 이제 이 작업을 원하는 페이지까지(또는 끝까지) **반복** 진행하면 됩니다.\n",
    "\n",
    "\n",
    "- 그렇다면 이제 마지막 페이지를 찾을 차례입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 마지막 페이지 번호 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![last_page](webcrawling/get_last_page.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"pgRR\">\n",
       "<a href=\"/sise/sise_index_day.naver?code=KPI200&amp;page=713\">맨뒤\n",
       "\t\t\t\t<img alt=\"\" border=\"0\" height=\"5\" src=\"https://ssl.pstatic.net/static/n/cmn/bu_pgarRR.gif\" width=\"8\"/>\n",
       "</a>\n",
       "</td>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 역시 해당 tag의 xpath를 복사해옵니다. 하지만 규칙이 간단해서 xpath를 굳이 사용하진 않겠습니다.\n",
    "source.find_all(\"td\", class_=\"pgRR\")[0]\n",
    "# /html/body/div/table[2]/tbody/tr/td[7]/a\n",
    "\n",
    "# td tag중에 class가 pgRR인 태그를 찾아서, 그 하위에 있는 a tag의 href 속성값을 가져옵니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에 최종적으로 가져온 문자열에서 마지막 3글자를 때어내면 우리가 원하는 마지막 페이지 숫자인 591이 나옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 글자를 때어내기 위해서 규칙을 생각해봅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 진짜 마지막 단계입니다. 해당 페이지 주소의 규칙을 찾아야 합니다.\n",
    "\n",
    "\n",
    "- 이제 크롤링의 과정은 다음과 같습니다.\n",
    "\n",
    "1) 일별 시세 정보가 있는 페이지에 접속한다.\n",
    "\n",
    "\n",
    "2) 페이지에서 날짜 / 체결가가 들어있는 태그를 검색한다.\n",
    "\n",
    "\n",
    "3) 태그 중에서 우리가 찾은 조건에 맞는 데이터만 가져온다.\n",
    "\n",
    "\n",
    "4) 이를 원하는만큼(현재는 마지막페이지까지) 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 페이지에 접속하는 예시\n",
    "naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(100)\n",
    "\n",
    "# 위에서 작성했던 모든 코드를 종합합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 가져온 모든 정보를 하나로 합쳐서 구현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 구현한 모든 내용을 하나의 코드로 구현합니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
